# FinCLI Environment Configuration Template
# Copy this file to .env and fill in your values
# DO NOT commit .env to version control!

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================
FINCLI_DEBUG=false
FINCLI_LOG_LEVEL=INFO
FINCLI_LOG_FORMAT=console  # Options: console, json
# FINCLI_LOG_FILE=./fincli.log  # Optional: Log to file

# =============================================================================
# GMAIL API CONFIGURATION
# =============================================================================
# Download credentials.json from Google Cloud Console
# See: docs/INSTALLATION.md for setup instructions
FINCLI_GMAIL_CREDENTIALS_PATH=credentials.json
FINCLI_GMAIL_TOKEN_PATH=token.json
FINCLI_GMAIL_MAX_RESULTS=100

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================
# Main provider: Choose one - "ollama", "bedrock", "openai", or "anthropic"
# Recommended: ollama (free, local) or anthropic (best quality)
FINCLI_LLM_PROVIDER=ollama

# Optional: Override provider for specific use cases
# This allows mixing providers (e.g., free Ollama for chat, paid Claude for extraction)
# FINCLI_LLM_EXTRACTION_PROVIDER=anthropic  # For structured data extraction
# FINCLI_LLM_CHAT_PROVIDER=openai           # For conversations
# FINCLI_LLM_SUMMARY_PROVIDER=ollama        # For summaries
# FINCLI_LLM_ANALYSIS_PROVIDER=anthropic    # For analysis

# -----------------------------------------------------------------------------
# OLLAMA CONFIGURATION (Local, Free)
# -----------------------------------------------------------------------------
# Install: https://ollama.ai
# Run: ollama pull llama3
FINCLI_OLLAMA_BASE_URL=http://localhost:11434
FINCLI_OLLAMA_MODEL_NAME=llama3  # Options: llama3, mistral, phi, codellama
FINCLI_OLLAMA_MAX_TOKENS=2048
FINCLI_OLLAMA_TEMPERATURE=0.0
FINCLI_OLLAMA_TIMEOUT=120

# -----------------------------------------------------------------------------
# AWS BEDROCK CONFIGURATION (Cloud, Enterprise)
# -----------------------------------------------------------------------------
# Requires: AWS CLI configured with credentials
# Enable model access in AWS Console: Bedrock > Model access
# FINCLI_BEDROCK_REGION=us-east-1
# FINCLI_BEDROCK_MODEL_ID=anthropic.claude-3-sonnet-20240229-v1:0
# FINCLI_BEDROCK_MAX_TOKENS=2048
# FINCLI_BEDROCK_TEMPERATURE=0.0
# FINCLI_BEDROCK_TIMEOUT=60

# -----------------------------------------------------------------------------
# ANTHROPIC CONFIGURATION (Cloud, Direct API)
# -----------------------------------------------------------------------------
# Get API key from: https://anthropic.com
# FINCLI_ANTHROPIC_API_KEY=sk-ant-api03-your-key-here
# FINCLI_ANTHROPIC_MODEL_NAME=claude-3-sonnet-20240229
# FINCLI_ANTHROPIC_MAX_TOKENS=2048
# FINCLI_ANTHROPIC_TEMPERATURE=0.0
# FINCLI_ANTHROPIC_TIMEOUT=60

# -----------------------------------------------------------------------------
# OPENAI CONFIGURATION (Cloud, GPT)
# -----------------------------------------------------------------------------
# Get API key from: https://openai.com
# FINCLI_OPENAI_API_KEY=sk-your-key-here
# FINCLI_OPENAI_MODEL_NAME=gpt-4  # Options: gpt-4, gpt-3.5-turbo
# FINCLI_OPENAI_MAX_TOKENS=2048
# FINCLI_OPENAI_TEMPERATURE=0.0
# FINCLI_OPENAI_TIMEOUT=60

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
# SQLite (default, recommended for local use)
FINCLI_DATABASE_URL=sqlite:///./fincli.db

# PostgreSQL (for production)
# FINCLI_DATABASE_URL=postgresql://user:password@localhost:5432/fincli

# MySQL (for production)
# FINCLI_DATABASE_URL=mysql://user:password@localhost:3306/fincli

FINCLI_DATABASE_ECHO=false  # Set to true for SQL query logging

# =============================================================================
# RETRY CONFIGURATION
# =============================================================================
FINCLI_MAX_RETRIES=3
FINCLI_RETRY_MIN_WAIT=1  # Seconds
FINCLI_RETRY_MAX_WAIT=10  # Seconds

# =============================================================================
# EMAIL PROCESSING
# =============================================================================
# Gmail search query to find transaction emails
# Customize based on your bank's email format
FINCLI_EMAIL_QUERY=subject:("transaction alert" OR "debited" OR "credited" OR "spent on" OR "payment received")

# Number of emails to process in a single batch
FINCLI_BATCH_SIZE=10

# =============================================================================
# EXAMPLE CONFIGURATIONS
# =============================================================================

# Example 1: Free Local Setup (Ollama)
# -------------------------------------
# FINCLI_LLM_PROVIDER=ollama
# FINCLI_OLLAMA_MODEL_NAME=llama3

# Example 2: Best Quality (Anthropic Claude)
# -------------------------------------------
# FINCLI_LLM_PROVIDER=anthropic
# FINCLI_ANTHROPIC_API_KEY=your-key

# Example 3: Hybrid Strategy (Cost Optimization)
# -----------------------------------------------
# FINCLI_LLM_PROVIDER=ollama  # Default: free for most tasks
# FINCLI_LLM_EXTRACTION_PROVIDER=anthropic  # Pay only for critical extraction
# FINCLI_ANTHROPIC_API_KEY=your-key

# Example 4: Enterprise Setup (AWS Bedrock)
# ------------------------------------------
# FINCLI_LLM_PROVIDER=bedrock
# FINCLI_BEDROCK_REGION=us-east-1
# (AWS credentials configured via AWS CLI)
