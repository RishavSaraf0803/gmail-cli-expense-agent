# Multi-Client LLM Configuration Example
# This shows how to use different LLMs for different use cases

# ====================================================================
# SCENARIO 1: Use different models for different tasks
# ====================================================================
# - Anthropic Claude for extraction (best accuracy)
# - OpenAI GPT-4 for chat (best conversation)
# - Local Ollama for summaries (cost-effective)
# ====================================================================

# Default provider (fallback)
FINCLI_LLM_PROVIDER=ollama

# Use-case specific providers (optional - overrides default)
FINCLI_LLM_EXTRACTION_PROVIDER=anthropic  # Claude for extraction
FINCLI_LLM_CHAT_PROVIDER=openai           # GPT-4 for chat
FINCLI_LLM_SUMMARY_PROVIDER=ollama        # Llama 3 for summaries
FINCLI_LLM_ANALYSIS_PROVIDER=ollama       # Llama 3 for analysis

# ====================================================================
# Provider Configurations
# ====================================================================

# Anthropic Claude (for extraction)
FINCLI_ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxx
FINCLI_ANTHROPIC_MODEL_NAME=claude-3-5-sonnet-20241022
FINCLI_ANTHROPIC_MAX_TOKENS=2048
FINCLI_ANTHROPIC_TEMPERATURE=0.0
FINCLI_ANTHROPIC_TIMEOUT=60

# OpenAI GPT (for chat)
FINCLI_OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxx
FINCLI_OPENAI_MODEL_NAME=gpt-4
FINCLI_OPENAI_MAX_TOKENS=2048
FINCLI_OPENAI_TEMPERATURE=0.7  # Higher for creative chat
FINCLI_OPENAI_TIMEOUT=60

# Ollama (for summaries - free, local)
FINCLI_OLLAMA_BASE_URL=http://localhost:11434
FINCLI_OLLAMA_MODEL_NAME=llama3
FINCLI_OLLAMA_MAX_TOKENS=2048
FINCLI_OLLAMA_TEMPERATURE=0.3
FINCLI_OLLAMA_TIMEOUT=120

# ====================================================================
# SCENARIO 2: All-in-one with a single provider
# ====================================================================
# Uncomment to use only one provider for everything
# ====================================================================

# Option A: All Ollama (100% free, local)
# FINCLI_LLM_PROVIDER=ollama

# Option B: All Claude (best quality)
# FINCLI_LLM_PROVIDER=anthropic
# FINCLI_ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxx

# Option C: All GPT-4 (best for chat)
# FINCLI_LLM_PROVIDER=openai
# FINCLI_OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxx

# Option D: All AWS Bedrock (enterprise)
# FINCLI_LLM_PROVIDER=bedrock
# AWS credentials via AWS CLI

# ====================================================================
# Other Settings (keep as-is from .env.example)
# ====================================================================

FINCLI_DEBUG=false
FINCLI_LOG_LEVEL=INFO

# Gmail API Configuration
FINCLI_GMAIL_CREDENTIALS_PATH=credentials.json
FINCLI_GMAIL_TOKEN_PATH=token.json

# Database
FINCLI_DATABASE_URL=sqlite:///./fincli.db

# Email Query
FINCLI_EMAIL_QUERY=subject:("transaction alert" OR "debited" OR "credited")
